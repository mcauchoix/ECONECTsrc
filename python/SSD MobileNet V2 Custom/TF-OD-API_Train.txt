  Followed tutorial :
  https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html
  (from https://github.com/sglvladi/TensorFlowObjectDetectionTutorial)
  
  ****************************************************************************************************************
  ********** Installation de l'environment virtuel et des dépendances, à n'éxecuter qu'une seule FOIS ! **********
  ****************************************************************************************************************
  conda create -n tf2 pip python=3.8
  conda activate tf2
  pip install tensorflow-gpu  # =2.5.0 pour le GPU de Florent

  mkdir C:\tf2
  cd C:\tf2
  git clone https://github.com/tensorflow/models.git

  conda install -c anaconda protobuf
  cd models\research
  protoc object_detection\protos\*.proto --python_out=.
  => * Fermer ce terminal et en ouvrir un nouveau ! *

  conda activate tf2
  pip install cython
  pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI
  
  cd C:\tf2\models\research
  copy object_detection\packages\tf2\setup.py .
  python -m pip install .
  
  # Afin d'éviter une erreur de compilation quand on veut évaluer le modèle avec COCO et PASCAL VOC 2010 
  pip install numpy==1.17.3 --user
  pip install IPython

  # Teste si l'installation s'est bien déroulée :
  python object_detection\builders\model_builder_tf2_test.py
 
  # Création des dossiers contenant les fichiers d'entrainement et les images
  cd C:\tf2
  git clone https://github.com/armaanpriyadarshan/Training-a-Custom-TensorFlow-2.X-Object-Detector
  move Training-a-Custom-TensorFlow-2.X-Object-Detector\scripts .
  move Training-a-Custom-TensorFlow-2.X-Object-Detector\workspace .
  rd /s /q Training-a-Custom-TensorFlow-2.X-Object-Detector
  del /q workspace\training_demo\images\*
  del /q workspace\training_demo\annotations\*
  rmdir /s /q workspace\training_demo\images\
  mkdir workspace\training_demo\images

  ****************************************************************************************************************
  ****************************************************************************************************************

  ****************************************************************************************************************
  ************************ Phase de préparation du dataset pour l'entraînement du réseau *************************
  ****************************************************************************************************************
  ********
  ******** Déplacer nos images + annotations dans le dossier "workspace\training_demo\images" avec le clone de GitLab puis en déplaçant le dossier raw_data (à renommer en JPEGImages) 
  ******** et également le dossier "Annotations" au même emplacement ("workspace\training_demo\images") en format PASCAL VOC
  ******** (ou modifier la commande ci-dessous avec les bons noms de dossiers)
  ******** Copier les fichiers train_test_splitter.py et xml_to_csv.py dans "scripts\preprocessing"
  ********

  conda activate tf2
  cd C:\tf2\scripts\preprocessing

  # Répartir les données de TRAIN et TEST
  # Pour faire une commande sur plusieurs lignes :
  # On met des "^" à la fin de chaque ligne sauf la dernière sur Windows
  # ou des "\" sur Linux
  python train_test_splitter.py ^
    --annotations=../../workspace/training_demo/images/Annotations/ ^
    --images=../../workspace/training_demo/images/JPEGImages/ ^
    --testsize=0.2 ^
    --outputdir=../../workspace/training_demo/images/
    # TODO param : classes à exclure : default = ['noBird', 'human', 'unknown'], si on veut exclure les 'MESCHA' par exemple

# Génération des fichiers CSV pour le comptage et TFRecords pour l'entrainement
# Adapter la fonction xml_to_csv(path) du fichier generate_tfrecord.py
# à l'aide du fichier xml_to_csv_MODIFIED.py situé dans C:\tf2\scripts\preprocessing
# Puis lancer les commandes

python generate_tfrecord.py ^
  -x C:\tf2\workspace\training_demo\images\train ^
  -l C:\tf2\workspace\training_demo\annotations\labelmap.pbtxt ^
  -o C:\tf2\workspace\training_demo\annotations\train.record ^
  -c C:\tf2\workspace\training_demo\annotations\train.csv

python generate_tfrecord.py ^
  -x C:\tf2\workspace\training_demo\images\test ^
  -l C:\tf2\workspace\training_demo\annotations\labelmap.pbtxt ^
  -o C:\tf2\workspace\training_demo\annotations\test.record ^
  -c C:\tf2\workspace\training_demo\annotations\test.csv

# Si on veut voir le nombre d'images par espèce maintenant :
# Le comptage est également réalisé dans l'inférence (étape finale après l'entrainement et l'évaluation)
python xml_to_csv_MODIFIED.py

****************************************************************************************************************
*************************************** À n'éxecuter qu'une seule FOIS ! ***************************************
****************************************************************************************************************
# Mise en place du modèle à entraîner 
Télécharger le modèle suivant : http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz
Puis l'extraire dans le dossier : C:\tf2\workspace\training_demo\pre-trained-models

cd C:\tf2\workspace\training_demo
mkdir models\my_ssd_mobilenet_v2_fpnlite
copy C:\tf2\workspace\training_demo\pre-trained-models\ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8\pipeline.config models\my_ssd_mobilenet_v2_fpnlite
****************************************************************************************************************
****************************************************************************************************************

****************************************************************************************************************
**************************************  Configuration de l'entrainement  ***************************************
****************************************************************************************************************
# TODO automatiser la modification avec un script python :
# AVEC DES "/" dans les chemins !!
#Ligne 3 : num_classes: 12
#Ligne 135 : batch_size: 6
#Ligne 165 : fine_tune_checkpoint: "pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0"
#Ligne 171 : fine_tune_checkpoint_type: "detection"
#Ligne 175 : label_map_path: "annotations/labelmap.pbtxt"
#Ligne 177 : input_path: "annotations/train.record"
#Ligne 185 : label_map_path: "annotations/labelmap.pbtxt"
#Ligne 189 : input_path: "annotations/test.record"


****************************************************************************************************************
**** Pour chaque script ci-dessous, on doit d'abord lancer les 2 prochaines commandes sur un SHELL Anaconda ****
****************************************************************************************************************
conda activate tf2
cd C:\tf2\workspace\training_demo
****************************************************************************************************************

# Lancement de l'entrainement :
python model_main_tf2.py ^
  --model_dir=models\my_ssd_mobilenet_v2_fpnlite ^
  --pipeline_config_path=models\my_ssd_mobilenet_v2_fpnlite\pipeline.config

# Pour suivre l'évolution des courbes d'apprentissage / LOSS :
# Sur une nouvelle console Anaconda
tensorboard --logdir=models\my_ssd_mobilenet_v2_fpnlite

****************************************************************************************************************
**** Après l'entrainement ****
****************************************************************************************************************
# Exporter le modèle final en TF2 :
python .\exporter_main_v2.py ^
  --input_type image_tensor ^
  --pipeline_config_path .\models\my_ssd_mobilenet_v2_fpnlite\pipeline.config ^
  --trained_checkpoint_dir .\models\my_ssd_mobilenet_v2_fpnlite\ ^
  --output_directory .\exported-models\my_mobilenet_model

# Ensuite => conversion en TF Lite :
python convert-to-tflite.py ^
  --model exported_models/my_mobilenet_model/saved_model ^
  --output TFLite_model

# Evaluation du modèle :
python model_main_tf2.py ^
  --pipeline_config_path models\my_ssd_mobilenet_v2_fpnlite\pipeline.config ^
  --model_dir models\my_ssd_mobilenet_v2_fpnlite ^
  --checkpoint_dir models\my_ssd_mobilenet_v2_fpnlite ^
  --alsologtostderr

# Inférence avec notre script personnalisé qui permet de comparer les boxes prédites et les annotations, avec l'affichage des classes prédites/annotées
# Notre script fournit aussi le comptage du nombre d'images par espèce en TRAIN et en TEST
python tf2_inference_OD_model.py